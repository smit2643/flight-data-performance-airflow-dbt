# âœˆï¸ **Flight Data Engineering Platform**

### **An End-to-End Modern Data Pipeline (Airflow + Snowflake + dbt + Streamlit)**

![Architecture Banner](https://dummyimage.com/1200x280/001122/ffffff\&text=Flight+Data+Pipeline+-+Airflow+Snowflake+dbt+Streamlit)

---
## ğŸŒŸ **Streamlite Dashboard** 

https://flight-data-performance-airflow-dbt-mw6pkagwhhqyxmtplqjvqe.streamlit.app/


## ğŸŒŸ **Overview**

This repository contains a complete **end-to-end data engineering project**, built with a modern data stack:

| Layer              | Technology            | Purpose                                                            |
| ------------------ | --------------------- | ------------------------------------------------------------------ |
| **Ingestion**      | Python, Airflow, APIs | Fetch flight, airport, BTS, & weather datasets from public sources |
| **Storage**        | AWS S3                | Raw zone storage for ingestion                                     |
| **Warehouse**      | Snowflake             | RAW â†’ STAGING â†’ MARTS transformation                               |
| **Transformation** | dbt Core              | Modular SQL modeling for analytics                                 |
| **Orchestration**  | Apache Airflow        | Full DAG automation (ingest â†’ stage â†’ load â†’ transform)            |
| **Visualization**  | Streamlit             | Interactive dashboard connected to live Snowflake data             |

This project is built exactly like a **real enterprise pipeline** and is designed for learning, demos, and production inspiration.

---

# ğŸ—ï¸ **Architecture**

```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚ Public Data Sources  â”‚
                â”‚  (GitHub, BTS, NOAA) â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  Airflow DAG     â”‚
                 â”‚ fetch â†’ S3 uploadâ”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚        AWS S3            â”‚
            â”‚  (Raw Landing Bucket)    â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ Stage in Snowflake
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚       Snowflake RAW      â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚ dbt models
                       â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   STAGING_MARTS / JFK    â”‚
            â”‚  Analytics-ready tables  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚        Streamlit App       â”‚
           â”‚  (Auto-refresh Snowflake)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸš€ **Features**

### âœ… Automated Ingestion Pipeline

* Downloads CSV + ZIP files
* Extracts, uploads to S3
* Snowflake COPY INTO staging tables

### âœ… dbt Transformation

* RAW â†’ STAGING
* STAGING â†’ MARTS/MARTS_JFK
* Includes:

  * Airline On-Time Ranking
  * Airport Daily Performance
  * Hourly Delay Distribution
  * Weather Delay Impact (JFK AIRPORT)

### âœ… Streamlit Dashboard

* Schema & table selector
* Pagination (250 rows per batch)
* Interactive charts using Altair
* Supports STAGING_MARTS and STAGING_MARTS_JFK

---

# ğŸ“ **Repository Structure**

```
flight_project/
â”‚
â”œâ”€â”€ dags/
â”‚   â”œâ”€â”€ flight_pipeline.py
â”‚   â”œâ”€â”€ upload_to_s3.py
â”‚   â””â”€â”€ dbt_runner.py
â”‚
â”œâ”€â”€ dbt/
â”‚   â”œâ”€â”€ logs/
â”‚   â””â”€â”€ flight_project/
â”‚       â”œâ”€â”€ analyses/
â”‚       â”œâ”€â”€ models/
â”‚       â”œâ”€â”€ macros/
â”‚       â”œâ”€â”€ seeds/
â”‚       â”œâ”€â”€ snapshots/
â”‚       â”œâ”€â”€ logs/  (NOT in Git)
â”‚       â”œâ”€â”€ target/ 
â”‚       â”œâ”€â”€ tests/
â”‚       â”œâ”€â”€ dbt_project.yml
â”‚       â””â”€â”€ packages.yml
â”‚
â”œâ”€â”€ logs/ (NOT in Git)
â”œâ”€â”€ plugins/ (NOT in Git)
â”‚
â”œâ”€â”€ streamlit/
â”‚   â”œâ”€â”€ dashboard.py
â”‚   â””â”€â”€ .streamlit/secrets.toml (NOT in Git)
â”‚
â”œâ”€â”€ .env (NOT in Git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ 01_db_setup.sql
â”œâ”€â”€ 02_create_load_tables.sql
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

# âš™ï¸ **Setup Instructions**

## **1ï¸âƒ£ Clone this repository**

```bash
git clone https://github.com/YOUR_USERNAME/flight-data-performance-airflow-dbt.git
cd flight-data-performance-airflow-dbt
```

---

# **2ï¸âƒ£ Airflow Setup (Docker)**

### Start containers:

```bash
cd flight_project
docker-compose up --build -d
```

### Verify Airflow UI

```
http://localhost:8081
```

Login:

```
username: airflow
password: airflow
```

---

# **3ï¸âƒ£ Configure Connections in Airflow UI**

### Create `aws_default`

Fill:

* Access Key
* Secret Key

### Create `snowflake_default`

Fill:

* Account
* Username & Password
* Role
* Warehouse
* Database

---

# **4ï¸âƒ£ Run the DAG**

Enable:

```
flight_daily_pipeline
```

This executes:

1. Download + upload to S3
2. Create Snowflake stages
3. COPY INTO tables
4. dbt run
5. Dashboard auto-refreshes

---

# **5ï¸âƒ£ Streamlit Setup (Local or Cloud)**

### Install dependencies

```bash
pip install -r requirements.txt
```

### Create secrets file

`streamlit/.streamlit/secrets.toml`

```
[snowflake]
account = "xxxx"
user = "xxxx"
password = "xxxx"
database = "FLIGHT"
warehouse = "FLIGHT_WH"
role = "ACCOUNTADMIN"
```

### Run Streamlit

```bash
cd streamlit
streamlit run dashboard.py
```

---

# ğŸŒ **Deploy Streamlit Online (Public Access)**

You can deploy using:

* **Streamlit Cloud** (recommended)
* **Railway**
* **Render**
* **AWS ECS**

Just upload your repo â†’ add secrets â†’ deploy.

---

# ğŸ“Š **Dashboard Preview**

* Pagination (250 rows at a time)
* Automatic chart builder
* STAGING_MARTS + JFK schema selector
* Auto-refresh every 5 minutes

---


---

# ğŸ‰ **Conclusion**

This repository demonstrates a **full production-grade data pipeline**:

âœ” Airflow orchestration
âœ” Snowflake ELT
âœ” dbt transformations
âœ” Automated staging & ingestion
âœ” Interactive Streamlit dashboard
âœ” Real-world architecture


